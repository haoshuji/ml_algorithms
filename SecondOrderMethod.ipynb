{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Hessian using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: \n",
    "- TensorFlow implementation of K-means algorithm: https://codesachin.wordpress.com/2015/11/14/k-means-clustering-with-tensorflow/\n",
    "- Calculating Hessian in Theano (application for Newton's method): https://groups.google.com/forum/#!topic/theano-users/2c15kq68lp8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow has a function called tf.gradients() that computes gradient. In the past, I've tried to compute Hessian of an neural network objective function in Torch7 using [torch-autograd](https://github.com/twitter/torch-autograd) but it was somewhat cumbersome; there wasn't an easy way to store/reshape parameters because Lua uses table for everything. Today, I'd like to do the same thing in TensorFlow. It should be much easier than in Torch7 due to the symbolic differentiation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 : Quadratic function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use $f(x) = \\frac{1}{2} x^T A x + b^T x + c$ as our first example to compute Hessian. When A is a symmetric matrix, the hessian of $f$ should be equal to $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, let us start with:\n",
    "$$ \n",
    "  A = \\left[\n",
    "    \\begin{array}{rrr}\n",
    "      2 & 2 & 2 \\\\\n",
    "      2 & 2 & 2 \\\\\n",
    "      2 & 2 & 2\n",
    "    \\end{array}\n",
    "  \\right]\n",
    "  \\quad\n",
    "  b = \\left[\n",
    "    \\begin{array}{rrr}\n",
    "      3  \\\\\n",
    "      3  \\\\\n",
    "      3 \n",
    "    \\end{array}\n",
    "  \\right]\n",
    "  \\quad\n",
    "  c = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below calculates the hessian for f(x).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getHessian(dim):\n",
    "    # Each time getHessian is called, we create a new graph so that the default graph (which exists a priori) won't be filled with old ops.\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "        # First create placeholders for inputs: A, b, and c.\n",
    "        A = tf.placeholder(tf.float32, shape=[dim, dim])\n",
    "        b = tf.placeholder(tf.float32, shape=[dim, 1])\n",
    "        c = tf.placeholder(tf.float32, shape=[1])\n",
    "\n",
    "        # Define our variable\n",
    "        x = tf.Variable(np.float32(np.repeat(1,dim).reshape(dim,1)))\n",
    "\n",
    "        # Construct the computational graph for quadratic function: f(x) = 1/2 * x^t A x + b^t x + c\n",
    "        fx = 0.5 * tf.matmul(tf.matmul(tf.transpose(x), A), x) + tf.matmul(tf.transpose(b), x) + c\n",
    "        \n",
    "        # Get gradients of fx with repect to x\n",
    "        dfx = tf.gradients(fx, x)[0]\n",
    "        # Compute hessian\n",
    "        for i in range(dim):\n",
    "            # Take the i th value of the gradient vector dfx \n",
    "            # tf.slice: https://www.tensorflow.org/versions/0.6.0/api_docs/python/array_ops.html#slice\n",
    "            dfx_i = tf.slice(dfx, begin=[i,0] , size=[1,1])\n",
    "            # Feed it to tf.gradients to compute the second derivative. \n",
    "            # Since x is a vector and dfx_i is a scalar, this will return a vector : [d(dfx_i) / dx_i , ... , d(dfx_n) / dx_n]\n",
    "            ddfx_i = tf.gradients(dfx_i, x)[0] # whenever we use tf.gradients, make sure you get the actual tensors by putting [0] at the end\n",
    "            if i == 0: hess = ddfx_i\n",
    "            else: hess = tf.concat(1, [hess, ddfx_i]) \n",
    "            ## Instead of doing this, you can just append each element to a list, and then do tf.pack(list_object) to get the hessian matrix too.\n",
    "            ## I'll use this alternative in the second example.  \n",
    "\n",
    "        # Before we execute the graph, we need to initialize all the variables we defined\n",
    "        init_op = tf.initialize_all_variables()\n",
    "    \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_op)\n",
    "            # We need to feed actual values into the computational graph that we created above. \n",
    "            feed_dict = {A: np.float32(np.repeat(2,dim*dim).reshape(dim,dim)), b: np.float32(np.repeat(3,dim).reshape(dim,1)) , c: [1]}\n",
    "            # sess.run() executes the graph. Here, \"hess\" will be calculated with the values in \"feed_dict\".\n",
    "            print(sess.run(hess, feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  2.  2.]\n",
      " [ 2.  2.  2.]\n",
      " [ 2.  2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "getHessian(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the result of sess.run(hess, feed_dict) is indeed the desired value: A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 : Multilayer Perceptron\n",
    "\n",
    "Next, we'll try a small neural network model: Multilayer perceptron. We need to modify our getHessian function a little bit; we need to create one-long vector for parameters, and then slice them according to the model architecture. Otherwise tf.gradients() cannot calculate the hessian matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getHessianMLP(n_input, n_hidden, n_output):\n",
    "    batch_size = 1\n",
    "\n",
    "    # Each time getHessianMLP is called, we create a new graph so that the default graph (which exists a priori) won't be filled with old ops.\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "        # First create placeholders for inputs and targets: x_input, y_target\n",
    "        x_input = tf.placeholder(tf.float32, shape=[batch_size, n_input])\n",
    "        y_target = tf.placeholder(tf.float32, shape=[batch_size, n_output])\n",
    "    \n",
    "        # Start constructing a computational graph for multilayer perceptron\n",
    "        ###  Since we want to store parameters as one long vector, we first define our parameters as below and then\n",
    "        ### reshape it later according to each layer specification.\n",
    "        parameters = tf.Variable(tf.concat(0, [tf.truncated_normal([n_input * n_hidden, 1]), tf.zeros([n_hidden, 1]),\n",
    "                                                                                                      tf.truncated_normal([n_hidden * n_output,1]), tf.zeros([n_output, 1])]))\n",
    "        \n",
    "        with tf.name_scope(\"hidden\") as scope:\n",
    "            idx_from = 0 \n",
    "            weights = tf.reshape(tf.slice(parameters, begin=[idx_from, 0], size=[n_input*n_hidden, 1]), [n_input, n_hidden])\n",
    "            idx_from = idx_from + n_input*n_hidden\n",
    "            biases = tf.reshape(tf.slice(parameters, begin=[idx_from, 0], size=[n_hidden, 1]), [n_hidden]) # tf.Variable(tf.truncated_normal([n_hidden]))\n",
    "            hidden = tf.matmul(x_input, weights) + biases\n",
    "        with tf.name_scope(\"linear\") as scope:\n",
    "            idx_from = idx_from + n_hidden\n",
    "            weights = tf.reshape(tf.slice(parameters, begin=[idx_from, 0], size=[n_hidden*n_output, 1]), [n_hidden, n_output])\n",
    "            idx_from = idx_from + n_hidden*n_output\n",
    "            biases = tf.reshape(tf.slice(parameters, begin=[idx_from, 0], size=[n_output, 1]), [n_output]) \n",
    "            output = tf.nn.softmax(tf.matmul(hidden, weights) + biases)\n",
    "        # Define cross entropy loss\n",
    "        loss = -tf.reduce_sum(y_target * tf.log(output))\n",
    "        \n",
    "        \n",
    "        ### Note: We can call tf.trainable_variables to get GraphKeys.TRAINABLE_VARIABLES \n",
    "        ### because we are using g as our default graph inside the \"with\" scope. \n",
    "        # Get trainable variables\n",
    "        tvars = tf.trainable_variables()\n",
    "        # Get gradients of loss with repect to parameters\n",
    "        dloss_dw = tf.gradients(loss, tvars)[0]\n",
    "        dim, _ = dloss_dw.get_shape()\n",
    "        hess = []\n",
    "        for i in range(dim):\n",
    "            # tf.slice: https://www.tensorflow.org/versions/0.6.0/api_docs/python/array_ops.html#slice\n",
    "            dfx_i = tf.slice(dloss_dw, begin=[i,0] , size=[1,1])\n",
    "            ddfx_i = tf.gradients(dfx_i, parameters)[0] # whenever we use tf.gradients, make sure you get the actual tensors by putting [0] at the end\n",
    "            hess.append(ddfx_i)\n",
    "        hess = tf.squeeze(hess) \n",
    "        init_op = tf.initialize_all_variables()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_op)\n",
    "            feed_dict = {x_input: np.random.random([batch_size, n_input]), y_target: np.random.random([batch_size, n_output])}\n",
    "            #print(sess.run(loss, feed_dict))\n",
    "            print(hess.get_shape())\n",
    "            print(sess.run(hess, feed_dict))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 31)\n",
      "[[  2.19931314e-03  -1.42659002e-03   1.30957202e-03  -8.70158256e-04\n",
      "    8.50890204e-03  -5.51932165e-03   5.06659178e-03  -3.36654740e-03\n",
      "    7.25943921e-03  -4.70885402e-03   4.32260381e-03  -2.87219742e-03\n",
      "    1.87662840e-02  -1.21727986e-02   1.11743081e-02  -7.42488075e-03\n",
      "   -5.90046346e-02   8.59218910e-02  -2.69172415e-02  -1.75508182e-03\n",
      "    3.87416431e-03  -2.11908249e-03  -5.98554593e-03   1.32124824e-02\n",
      "   -7.22693698e-03   3.56099289e-03  -7.86052924e-03   4.29953635e-03\n",
      "   -1.33406427e-02   2.94481106e-02  -1.61074679e-02]\n",
      " [ -1.42659002e-03   2.15499196e-03   2.23391340e-03   5.85207134e-04\n",
      "   -5.51932165e-03   8.33742879e-03   8.64276756e-03   2.26410269e-03\n",
      "   -4.70885402e-03   7.11314566e-03   7.37364776e-03   1.93163764e-03\n",
      "   -1.21727986e-02   1.83881018e-02   1.90615226e-02   4.99345176e-03\n",
      "   -2.40529864e-03  -1.63234770e-02   1.87287778e-02  -5.11422716e-02\n",
      "    6.40287027e-02  -1.28864162e-02  -1.72071008e-03  -1.16775408e-02\n",
      "    1.33982506e-02   1.02370558e-03   6.94734277e-03  -7.97104836e-03\n",
      "   -3.83513537e-03  -2.60270163e-02   2.98621524e-02]\n",
      " [  1.30957307e-03   2.23391363e-03   8.51151627e-03  -4.66033816e-04\n",
      "    5.06659551e-03   8.64276849e-03   3.29301283e-02  -1.80303410e-03\n",
      "    4.32260707e-03   7.37364870e-03   2.80946065e-02  -1.53827318e-03\n",
      "    1.11743165e-02   1.90615244e-02   7.26270080e-02  -3.97657044e-03\n",
      "   -2.46225428e-02   1.05903557e-04   2.45166421e-02  -5.16493944e-03\n",
      "    2.22148210e-05   5.14272461e-03  -6.82522804e-02   6.75285533e-02\n",
      "    7.23740086e-04   1.04794614e-02  -4.50730113e-05  -1.04343891e-02\n",
      "   -3.92594859e-02   1.68858227e-04   3.90906297e-02]\n",
      " [ -8.70158023e-04   5.85206726e-04  -4.66033292e-04   3.44629283e-04\n",
      "   -3.36654671e-03   2.26410106e-03  -1.80303201e-03   1.33333320e-03\n",
      "   -2.87219672e-03   1.93163624e-03  -1.53827143e-03   1.13754405e-03\n",
      "   -7.42487889e-03   4.99344803e-03  -3.97656579e-03   2.94065056e-03\n",
      "    3.17802234e-03  -7.38068856e-03   4.20266483e-03   6.66636741e-04\n",
      "   -1.54820760e-03   8.81570508e-04   2.27350369e-03  -5.28002018e-03\n",
      "    3.00651556e-03  -5.19903041e-02   7.05940425e-02  -1.86037235e-02\n",
      "    5.06720692e-03  -1.17681604e-02   6.70095114e-03]\n",
      " [  8.50890391e-03  -5.51931979e-03   5.06659690e-03  -3.36654903e-03\n",
      "    3.29200253e-02  -2.13536471e-02   1.96021106e-02  -1.30248116e-02\n",
      "    2.80859862e-02  -1.82180386e-02   1.67236999e-02  -1.11122234e-02\n",
      "    7.26047233e-02  -4.70952168e-02   4.32322249e-02  -2.87260674e-02\n",
      "   -2.28282511e-01   3.32422405e-01  -1.04139864e-01  -6.79022353e-03\n",
      "    1.49887213e-02  -8.19849689e-03  -2.31574345e-02   5.11176623e-02\n",
      "   -2.79602241e-02   1.37770995e-02  -3.04115340e-02   1.66344326e-02\n",
      "   -5.16135171e-02   1.13931544e-01  -6.23180196e-02]\n",
      " [ -5.51931979e-03   8.33743159e-03   8.64277314e-03   2.26410129e-03\n",
      "   -2.13536471e-02   3.22566144e-02   3.34379487e-02   8.75956193e-03\n",
      "   -1.82180386e-02   2.75199953e-02   2.85278577e-02   7.47329136e-03\n",
      "   -4.70952168e-02   7.11415857e-02   7.37470016e-02   1.93191096e-02\n",
      "   -9.30584874e-03  -6.31537363e-02   7.24596083e-02  -1.97863877e-01\n",
      "    2.47720048e-01  -4.98561375e-02  -6.65724743e-03  -4.51791212e-02\n",
      "    5.18363789e-02   3.96060990e-03   2.68785059e-02  -3.08391228e-02\n",
      "   -1.48377381e-02  -1.00695662e-01   1.15533426e-01]\n",
      " [  5.06659225e-03   8.64276756e-03   3.29301171e-02  -1.80303084e-03\n",
      "    1.96020920e-02   3.34379263e-02   1.27403036e-01  -6.97572995e-03\n",
      "    1.67236850e-02   2.85278372e-02   1.08694941e-01  -5.95140085e-03\n",
      "    4.32321839e-02   7.37469494e-02   2.80985892e-01  -1.53848901e-02\n",
      "   -9.52619165e-02   4.09700442e-04   9.48522016e-02  -1.99825820e-02\n",
      "    8.59406719e-05   1.98966395e-02  -2.64060616e-01   2.61260569e-01\n",
      "    2.80006230e-03   4.05438840e-02  -1.74370289e-04  -4.03695107e-02\n",
      "   -1.51890635e-01   6.53248047e-04   1.51237369e-01]\n",
      " [ -3.36654717e-03   2.26410199e-03  -1.80303212e-03   1.33333285e-03\n",
      "   -1.30248042e-02   8.75956379e-03  -6.97573507e-03   5.15851984e-03\n",
      "   -1.11122178e-02   7.47329323e-03  -5.95140504e-03   4.40103328e-03\n",
      "   -2.87260525e-02   1.93191152e-02  -1.53849013e-02   1.13770543e-02\n",
      "    1.22954259e-02  -2.85550859e-02   1.62596572e-02   2.57914583e-03\n",
      "   -5.98984724e-03   3.41070117e-03   8.79594032e-03  -2.04278268e-02\n",
      "    1.16318837e-02  -2.01144829e-01   2.73120642e-01  -7.19757825e-02\n",
      "    1.96044780e-02  -4.55297381e-02   2.59252563e-02]\n",
      " [  7.25943968e-03  -4.70885402e-03   4.32260474e-03  -2.87219719e-03\n",
      "    2.80859806e-02  -1.82180442e-02   1.67236868e-02  -1.11122178e-02\n",
      "    2.39617843e-02  -1.55428723e-02   1.42679494e-02  -9.48047917e-03\n",
      "    6.19433001e-02  -4.01796810e-02   3.68838944e-02  -2.45078653e-02\n",
      "   -1.94761068e-01   2.83608884e-01  -8.88477862e-02  -5.79313235e-03\n",
      "    1.27877481e-02  -6.99461577e-03  -1.97569467e-02   4.36114408e-02\n",
      "   -2.38544960e-02   1.17540406e-02  -2.59458441e-02   1.41918045e-02\n",
      "   -4.40344773e-02   9.72016081e-02  -5.31671345e-02]\n",
      " [ -4.70885308e-03   7.11314194e-03   7.37364404e-03   1.93164009e-03\n",
      "   -1.82180386e-02   2.75199711e-02   2.85278261e-02   7.47330487e-03\n",
      "   -1.55428685e-02   2.34788861e-02   2.43387464e-02   6.37591118e-03\n",
      "   -4.01796699e-02   6.06949702e-02   6.29177839e-02   1.64822862e-02\n",
      "   -7.93935359e-03  -5.38801439e-02   6.18194789e-02  -1.68809175e-01\n",
      "    2.11344376e-01  -4.25351746e-02  -5.67967957e-03  -3.85449454e-02\n",
      "    4.42246124e-02   3.37902317e-03   2.29316223e-02  -2.63106376e-02\n",
      "   -1.26589248e-02  -8.59093517e-02   9.85682458e-02]\n",
      " [  4.32260614e-03   7.37364497e-03   2.80945953e-02  -1.53827167e-03\n",
      "    1.67236924e-02   2.85278298e-02   1.08694926e-01  -5.95140550e-03\n",
      "    1.42679540e-02   2.43387502e-02   9.27339643e-02  -5.07749012e-03\n",
      "    3.68839055e-02   6.29177913e-02   2.39725381e-01  -1.31257549e-02\n",
      "   -8.12734738e-02   3.49558628e-04   8.09239075e-02  -1.70483012e-02\n",
      "    7.33250417e-05   1.69749763e-02  -2.25285441e-01   2.22896591e-01\n",
      "    2.38888338e-03   3.45903449e-02  -1.48773674e-04  -3.44415680e-02\n",
      "   -1.29586726e-01   5.57354768e-04   1.29029363e-01]\n",
      " [ -2.87219672e-03   1.93163811e-03  -1.53826911e-03   1.13754277e-03\n",
      "   -1.11122159e-02   7.47329742e-03  -5.95139572e-03   4.40102909e-03\n",
      "   -9.48047731e-03   6.37590466e-03  -5.07748174e-03   3.75477388e-03\n",
      "   -2.45078616e-02   1.64822694e-02  -1.31257325e-02   9.70641803e-03\n",
      "    1.04899378e-02  -2.43619941e-02   1.38720619e-02   2.20041815e-03\n",
      "   -5.11028524e-03   2.90986826e-03   7.50432443e-03  -1.74281597e-02\n",
      "    9.92383901e-03  -1.71608344e-01   2.33015090e-01  -6.14067242e-02\n",
      "    1.67257115e-02  -3.88440527e-02   2.21183486e-02]\n",
      " [  1.87662840e-02  -1.21727977e-02   1.11743109e-02  -7.42488168e-03\n",
      "    7.26047084e-02  -4.70952280e-02   4.32321914e-02  -2.87260581e-02\n",
      "    6.19433001e-02  -4.01796773e-02   3.68838981e-02  -2.45078709e-02\n",
      "    1.60128832e-01  -1.03867970e-01   9.53480899e-02  -6.33549839e-02\n",
      "   -5.03474355e-01   7.33153701e-01  -2.29679257e-01  -1.49757518e-02\n",
      "    3.30574438e-02  -1.80816911e-02  -5.10734282e-02   1.12739384e-01\n",
      "   -6.16659559e-02   3.03852186e-02  -6.70722723e-02   3.66870500e-02\n",
      "   -1.13832958e-01   2.51274645e-01  -1.37441680e-01]\n",
      " [ -1.21727930e-02   1.83881000e-02   1.90615281e-02   4.99344710e-03\n",
      "   -4.70952131e-02   7.11415559e-02   7.37469718e-02   1.93191022e-02\n",
      "   -4.01796624e-02   6.06950000e-02   6.29178286e-02   1.64822489e-02\n",
      "   -1.03867933e-01   1.56901866e-01   1.62648082e-01   4.26080525e-02\n",
      "   -2.05239300e-02  -1.39284804e-01   1.59808770e-01  -4.36386436e-01\n",
      "    5.46343684e-01  -1.09957129e-01  -1.46824736e-02  -9.96420011e-02\n",
      "    1.14324503e-01   8.73507373e-03   5.92802167e-02  -6.80153072e-02\n",
      "   -3.27244401e-02  -2.22083062e-01   2.54807562e-01]\n",
      " [  1.11743147e-02   1.90615207e-02   7.26269931e-02  -3.97656346e-03\n",
      "    4.32322063e-02   7.37469494e-02   2.80985922e-01  -1.53848911e-02\n",
      "    3.68839093e-02   6.29178062e-02   2.39725441e-01  -1.31257446e-02\n",
      "    9.53481197e-02   1.62648022e-01   6.19711161e-01  -3.39311957e-02\n",
      "   -2.10099071e-01   9.03622946e-04   2.09195420e-01  -4.40713577e-02\n",
      "    1.89548155e-04   4.38818038e-02  -5.82382560e-01   5.76207101e-01\n",
      "    6.17551804e-03   8.94190744e-02  -3.84585845e-04  -8.90344754e-02\n",
      "   -3.34993064e-01   1.44078420e-03   3.33552241e-01]\n",
      " [ -7.42488354e-03   4.99345735e-03  -3.97656439e-03   2.94064917e-03\n",
      "   -2.87260655e-02   1.93191431e-02  -1.53848948e-02   1.13770505e-02\n",
      "   -2.45078765e-02   1.64822843e-02  -1.31257484e-02   9.70642362e-03\n",
      "   -6.33549988e-02   4.26081419e-02  -3.39312032e-02   2.50919517e-02\n",
      "    2.71174312e-02  -6.29779175e-02   3.58605087e-02   5.68827847e-03\n",
      "   -1.32105416e-02   7.52226682e-03   1.93993524e-02  -4.50533405e-02\n",
      "    2.56540030e-02  -4.43622559e-01   6.02364361e-01  -1.58741742e-01\n",
      "    4.32374664e-02  -1.00415327e-01   5.71778901e-02]\n",
      " [ -5.90046346e-02  -2.40530004e-03  -2.46225353e-02   3.17802420e-03\n",
      "   -2.28282496e-01  -9.30584315e-03  -9.52619091e-02   1.22954287e-02\n",
      "   -1.94761068e-01  -7.93935638e-03  -8.12734738e-02   1.04899453e-02\n",
      "   -5.03474355e-01  -2.05239281e-02  -2.10099012e-01   2.71174237e-02\n",
      "    8.17221180e-02  -4.25955653e-02  -3.91265601e-02   1.71424113e-02\n",
      "   -8.93504452e-03  -8.20736866e-03   5.84626272e-02  -3.04721501e-02\n",
      "   -2.79904809e-02  -3.47812884e-02   1.81288570e-02   1.66524332e-02\n",
      "    1.30302072e-01  -6.79166242e-02  -6.23854548e-02]\n",
      " [  8.59218836e-02  -1.63234770e-02   1.05899824e-04  -7.38069136e-03\n",
      "    3.32422405e-01  -6.31537586e-02   4.09714878e-04  -2.85550915e-02\n",
      "    2.83608884e-01  -5.38801402e-02   3.49551585e-04  -2.43620090e-02\n",
      "    7.33153701e-01  -1.39284864e-01   9.03621316e-04  -6.29779175e-02\n",
      "   -4.25955765e-02   1.70439810e-01  -1.27844244e-01  -8.93504638e-03\n",
      "    3.57522480e-02  -2.68172026e-02  -3.04721557e-02   1.21929772e-01\n",
      "   -9.14576128e-02   1.81288626e-02  -7.25399256e-02   5.44110648e-02\n",
      "   -6.79166391e-02   2.71758258e-01  -2.03841627e-01]\n",
      " [ -2.69172415e-02   1.87287796e-02   2.45166421e-02   4.20266762e-03\n",
      "   -1.04139879e-01   7.24596083e-02   9.48522165e-02   1.62596628e-02\n",
      "   -8.88477862e-02   6.18195049e-02   8.09239447e-02   1.38720637e-02\n",
      "   -2.29679272e-01   1.59808815e-01   2.09195450e-01   3.58604938e-02\n",
      "   -3.91265675e-02  -1.27844244e-01   1.66970819e-01  -8.20737053e-03\n",
      "   -2.68172026e-02   3.50245759e-02  -2.79904846e-02  -9.14576128e-02\n",
      "    1.19448103e-01   1.66524369e-02   5.44110648e-02  -7.10635036e-02\n",
      "   -6.23854659e-02  -2.03841627e-01   2.66227096e-01]\n",
      " [ -1.75508205e-03  -5.11422716e-02  -5.16493758e-03   6.66636974e-04\n",
      "   -6.79022120e-03  -1.97863877e-01  -1.99825801e-02   2.57914583e-03\n",
      "   -5.79313235e-03  -1.68809175e-01  -1.70483012e-02   2.20041932e-03\n",
      "   -1.49757527e-02  -4.36386436e-01  -4.40713465e-02   5.68827568e-03\n",
      "    1.71424150e-02  -8.93504545e-03  -8.20736866e-03   3.59587278e-03\n",
      "   -1.87425665e-03  -1.72161579e-03   1.22633949e-02  -6.39198069e-03\n",
      "   -5.87141281e-03  -7.29588605e-03   3.80279403e-03   3.49309156e-03\n",
      "    2.73327734e-02  -1.42465085e-02  -1.30862622e-02]\n",
      " [  3.87416431e-03   6.40286952e-02   2.22143226e-05  -1.54820841e-03\n",
      "    1.49887195e-02   2.47720033e-01   8.59447900e-05  -5.98984957e-03\n",
      "    1.27877481e-02   2.11344361e-01   7.33244960e-05  -5.11028897e-03\n",
      "    3.30574438e-02   5.46343625e-01   1.89550221e-04  -1.32105425e-02\n",
      "   -8.93504545e-03   3.57522517e-02  -2.68172026e-02  -1.87425676e-03\n",
      "    7.49955839e-03  -5.62530104e-03  -6.39198115e-03   2.55765561e-02\n",
      "   -1.91845745e-02   3.80279426e-03  -1.52163124e-02   1.14135174e-02\n",
      "   -1.42465094e-02   5.70052788e-02  -4.27587666e-02]\n",
      " [ -2.11908272e-03  -1.28864162e-02   5.14272414e-03   8.81570915e-04\n",
      "   -8.19849968e-03  -4.98561412e-02   1.98966395e-02   3.41070187e-03\n",
      "   -6.99461717e-03  -4.25351709e-02   1.69749800e-02   2.90986802e-03\n",
      "   -1.80816948e-02  -1.09957129e-01   4.38818038e-02   7.52226263e-03\n",
      "   -8.20736866e-03  -2.68172026e-02   3.50245722e-02  -1.72161579e-03\n",
      "   -5.62530104e-03   7.34691694e-03  -5.87141281e-03  -1.91845745e-02\n",
      "    2.50559878e-02   3.49309156e-03   1.14135174e-02  -1.49066094e-02\n",
      "   -1.30862622e-02  -4.27587666e-02   5.58450297e-02]\n",
      " [ -5.98554546e-03  -1.72071054e-03  -6.82522729e-02   2.27350486e-03\n",
      "   -2.31574234e-02  -6.65724184e-03  -2.64060616e-01   8.79594218e-03\n",
      "   -1.97569449e-02  -5.67968003e-03  -2.25285456e-01   7.50432955e-03\n",
      "   -5.10734245e-02  -1.46824680e-02  -5.82382560e-01   1.93993468e-02\n",
      "    5.84626310e-02  -3.04721482e-02  -2.79904827e-02   1.22633940e-02\n",
      "   -6.39197975e-03  -5.87141374e-03   4.18231823e-02  -2.17992608e-02\n",
      "   -2.00239196e-02  -2.48819496e-02   1.29690785e-02   1.19128712e-02\n",
      "    9.32159126e-02  -4.85864058e-02  -4.46295068e-02]\n",
      " [  1.32124806e-02  -1.16775399e-02   6.75285384e-02  -5.28002065e-03\n",
      "    5.11176474e-02  -4.51791286e-02   2.61260569e-01  -2.04278249e-02\n",
      "    4.36114371e-02  -3.85449417e-02   2.22896576e-01  -1.74281653e-02\n",
      "    1.12739369e-01  -9.96420383e-02   5.76207101e-01  -4.50533256e-02\n",
      "   -3.04721463e-02   1.21929750e-01  -9.14576128e-02  -6.39197929e-03\n",
      "    2.55765524e-02  -1.91845726e-02  -2.17992589e-02   8.72264877e-02\n",
      "   -6.54272288e-02   1.29690776e-02  -5.18938303e-02   3.89247537e-02\n",
      "   -4.85864021e-02   1.94411248e-01  -1.45824850e-01]\n",
      " [ -7.22693605e-03   1.33982496e-02   7.23737583e-04   3.00651696e-03\n",
      "   -2.79602278e-02   5.18363677e-02   2.80006183e-03   1.16318865e-02\n",
      "   -2.38544960e-02   4.42246199e-02   2.38889549e-03   9.92383901e-03\n",
      "   -6.16659522e-02   1.14324495e-01   6.17550313e-03   2.56539881e-02\n",
      "   -2.79904809e-02  -9.14576128e-02   1.19448088e-01  -5.87141328e-03\n",
      "   -1.91845726e-02   2.50559859e-02  -2.00239178e-02  -6.54272288e-02\n",
      "    8.54511485e-02   1.19128702e-02   3.89247537e-02  -5.08376248e-02\n",
      "   -4.46295030e-02  -1.45824850e-01   1.90454349e-01]\n",
      " [  3.56099289e-03   1.02370582e-03   1.04794577e-02  -5.19903041e-02\n",
      "    1.37770930e-02   3.96060618e-03   4.05438803e-02  -2.01144814e-01\n",
      "    1.17540397e-02   3.37902340e-03   3.45903412e-02  -1.71608344e-01\n",
      "    3.03852167e-02   8.73507001e-03   8.94190520e-02  -4.43622530e-01\n",
      "   -3.47812921e-02   1.81288570e-02   1.66524332e-02  -7.29588559e-03\n",
      "    3.80279357e-03   3.49309179e-03  -2.48819496e-02   1.29690794e-02\n",
      "    1.19128702e-02   1.48030687e-02  -7.71572068e-03  -7.08734803e-03\n",
      "   -5.54571301e-02   2.89056096e-02   2.65515205e-02]\n",
      " [ -7.86052924e-03   6.94734138e-03  -4.50721709e-05   7.05940425e-02\n",
      "   -3.04115303e-02   2.68785059e-02  -1.74379311e-04   2.73120642e-01\n",
      "   -2.59458460e-02   2.29316168e-02  -1.48773135e-04   2.33015105e-01\n",
      "   -6.70722723e-02   5.92802279e-02  -3.84591520e-04   6.02364361e-01\n",
      "    1.81288607e-02  -7.25399256e-02   5.44110611e-02   3.80279403e-03\n",
      "   -1.52163124e-02   1.14135174e-02   1.29690804e-02  -5.18938377e-02\n",
      "    3.89247537e-02  -7.71572161e-03   3.08733080e-02  -2.31575835e-02\n",
      "    2.89056133e-02  -1.15661494e-01   8.67558718e-02]\n",
      " [  4.29953542e-03  -7.97104649e-03  -1.04343863e-02  -1.86037254e-02\n",
      "    1.66344345e-02  -3.08391098e-02  -4.03695032e-02  -7.19757825e-02\n",
      "    1.41918035e-02  -2.63106376e-02  -3.44415680e-02  -6.14067279e-02\n",
      "    3.66870500e-02  -6.80152923e-02  -8.90344605e-02  -1.58741742e-01\n",
      "    1.66524313e-02   5.44110648e-02  -7.10634887e-02   3.49309156e-03\n",
      "    1.14135183e-02  -1.49066085e-02   1.19128693e-02   3.89247574e-02\n",
      "   -5.08376211e-02  -7.08734756e-03  -2.31575854e-02   3.02449297e-02\n",
      "    2.65515186e-02   8.67558792e-02  -1.13307387e-01]\n",
      " [ -1.33406427e-02  -3.83513607e-03  -3.92594710e-02   5.06720878e-03\n",
      "   -5.16134948e-02  -1.48377242e-02  -1.51890621e-01   1.96044799e-02\n",
      "   -4.40344736e-02  -1.26589248e-02  -1.29586726e-01   1.67257208e-02\n",
      "   -1.13832951e-01  -3.27244252e-02  -3.34992975e-01   4.32374477e-02\n",
      "    1.30302086e-01  -6.79166242e-02  -6.23854548e-02   2.73327697e-02\n",
      "   -1.42465075e-02  -1.30862631e-02   9.32159126e-02  -4.85864095e-02\n",
      "   -4.46295030e-02  -5.54571301e-02   2.89056115e-02   2.65515205e-02\n",
      "    2.07760528e-01  -1.08289860e-01  -9.94706675e-02]\n",
      " [  2.94481069e-02  -2.60270126e-02   1.68846658e-04  -1.17681650e-02\n",
      "    1.13931514e-01  -1.00695677e-01   6.53249328e-04  -4.55297455e-02\n",
      "    9.72016007e-02  -8.59093368e-02   5.57324965e-04  -3.88440751e-02\n",
      "    2.51274616e-01  -2.22083122e-01   1.44073367e-03  -1.00415319e-01\n",
      "   -6.79166168e-02   2.71758229e-01  -2.03841612e-01  -1.42465057e-02\n",
      "    5.70052713e-02  -4.27587628e-02  -4.85864021e-02   1.94411263e-01\n",
      "   -1.45824850e-01   2.89056059e-02  -1.15661487e-01   8.67558718e-02\n",
      "   -1.08289845e-01   4.33305711e-01  -3.25015843e-01]\n",
      " [ -1.61074679e-02   2.98621580e-02   3.90906222e-02   6.70095393e-03\n",
      "   -6.23180382e-02   1.15533434e-01   1.51237354e-01   2.59252600e-02\n",
      "   -5.31671420e-02   9.85682905e-02   1.29029378e-01   2.21183468e-02\n",
      "   -1.37441695e-01   2.54807621e-01   3.33552212e-01   5.71778566e-02\n",
      "   -6.23854510e-02  -2.03841627e-01   2.66227096e-01  -1.30862622e-02\n",
      "   -4.27587666e-02   5.58450334e-02  -4.46294993e-02  -1.45824865e-01\n",
      "    1.90454364e-01   2.65515186e-02   8.67558792e-02  -1.13307402e-01\n",
      "   -9.94706601e-02  -3.25015873e-01   4.24486548e-01]]\n"
     ]
    }
   ],
   "source": [
    "getHessianMLP(n_input=3,n_hidden=4,n_output=2) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
